Used Support Vector Machine (SVM) for Parkinson Disease Prediction (Heart)

Stemming and lemmatization are text normalization techniques that reduce words to their base form, but stemming simply chops off word endings (like "eating" to "eat") while lemmatization uses context and a dictionary to find the actual dictionary form (lemma) of a word (like "better" to "good"). Stemming is faster but can produce non-words, whereas lemmatization is slower and more complex but is more accurate and context-aware. 
